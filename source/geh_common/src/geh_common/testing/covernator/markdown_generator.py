import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List

from geh_common.testing.covernator.models import (
    CaseInfo,
    CoverageMapping,
    CovernatorResults,
)


# ==========================================================
# === Helpers ==============================================
# ==========================================================
def normalize_group_name(raw: str, prefix: str = "geh_") -> str:
    if prefix and raw.startswith(prefix):
        raw = raw[len(prefix) :]
    raw = raw.replace("_", " ").strip()
    return " ".join(word.capitalize() for word in raw.split())


def group_cases_by_group(cases: List[CaseInfo]) -> Dict[str, List[CaseInfo]]:
    grouped = {}
    for case in cases:
        group = case.group.strip()
        grouped.setdefault(group, []).append(case)
    return grouped


def get_coverage_dict(coverage_map: List[CoverageMapping]) -> Dict[tuple, int]:
    """Group CoverageMapping entries by (group, case), and count unique scenarios."""
    coverage_dict = defaultdict(set)
    for entry in coverage_map:
        key = (entry.group.lower().strip(), entry.case.lower().strip())
        coverage_dict[key].add(entry.scenario.strip().lower())
    return {k: len(v) for k, v in coverage_dict.items()}


def extract_bracket_tags(msg: str) -> list[str]:
    """Extract all bracketed tags from log messages."""
    return [m.group(1).strip().lower() for m in re.finditer(r"\[([^\[\]]+)\]", msg)]


# ==========================================================
# === Markdown Generator ===================================
# ==========================================================
def generate_markdown_from_results(
    results: CovernatorResults,
    output_path: Path,
    group_prefix: str = "geh_",
):
    output = []
    print("üîß [DEBUG] Markdown generation started")

    # --- Header ---
    normalized_prefix = normalize_group_name(group_prefix.rstrip("/"))
    output.append(f"# üî© Covernator Coverage Overview for {normalized_prefix}\n")

    now = datetime.now().astimezone().strftime("%Y-%m-%d %H:%M:%S %Z")
    output.append(f"Generated: {now}\n")

    # --- Summary Section ---
    total_cases = len(results.all_cases)
    implemented_cases = sum(1 for case in results.all_cases if case.implemented)
    coverage_pct = f"{(implemented_cases / total_cases * 100):.1f}" if total_cases > 0 else "0.0"

    output.extend(
        [
            "\n## üìä Summary",
            "| Metric | Value |",
            "|--------|--------|",
            f"| üìü Total Cases | {results.stats.total_cases} |",
            f"| üß† Total Scenarios | {results.stats.total_scenarios} |",
            f"| üíÇÔ∏è Total Groups | {results.stats.total_groups} |",
            f"| ‚öôÔ∏è Implemented Cases | {implemented_cases} / {total_cases} ({coverage_pct}%) |",
            "",
        ]
    )

    # --- Mapping: (group, case) -> scenario count ---
    coverage_dict = get_coverage_dict(results.coverage_map)
    grouped_cases = group_cases_by_group(results.all_cases)

    # ==========================================================
    # === Per-group section ====================================
    # ==========================================================
    for group, cases in grouped_cases.items():
        group_title = normalize_group_name(group, group_prefix)
        group_key = group[len(group_prefix) :] if group.startswith(group_prefix) else group
        group_normalized = group.strip().lower()
        group_key_normalized = group_key.strip().lower()

        print(f"üß© [DEBUG] Processing group: {group} ({group_key_normalized})")

        # Determine if group has any errors
        header_emoji = "üìÅ"
        for e in results.error_logs:
            tags = extract_bracket_tags(e.message)
            if any(
                g in tags
                for g in [group_normalized, group_key_normalized, f"geh_calculated_measurements/{group_key_normalized}"]
            ):
                header_emoji = "üö®"
                break

        output.append(f"## {header_emoji} {group_title}")
        output.append("### Case overview")
        output.append("| Path | Case | Implemented | Covered by # scenarios |")
        output.append("|----------|-----------|-------------|-------------|")

        for case in cases:
            case_key = (case.group.strip().lower(), case.case.strip().lower())
            covered = coverage_dict.get(case_key, 0)
            covered_icon = "‚úÖ" if covered > 0 else "‚ö†Ô∏è"
            impl_icon = "üß©" if case.implemented else "‚ö†Ô∏è"
            output.append(
                f"| {case.path.strip()} | {case.case.strip()} | {impl_icon} {str(case.implemented)} | {covered_icon} {covered} |"
            )

        output.append("")

        # --- Group-specific errors ---
        errors = []

        # Define equivalent name forms for matching
        all_group_aliases = {
            group_normalized,
            group_key_normalized,
            f"geh_calculated_measurements/{group_key_normalized}",
            f"calculated_measurements/{group_key_normalized}",
            group_key_normalized.split("/")[-1],  # <‚Äî plain short version
        }

        print(f"   [DEBUG] Alias set for {group}: {all_group_aliases}")

        for e in results.error_logs:
            tags = extract_bracket_tags(e.message)
            if tags:
                print(f"   [DEBUG] Tags in '{e.message[:60]}...': {tags}")

            # Check intersection of tags with aliases
            if any(tag in all_group_aliases for tag in tags):
                errors.append(e.message)
                print(f"‚úÖ [DEBUG] Matched error for {group}: {e.message}")

        # ‚úÖ Output errors under the group
        if errors:
            output.append(f"### ‚ùå {group_title} Coverage Errors")
            for err in errors:
                output.append(f"- {err}")
            output.append("")
        else:
            print(f"‚ö†Ô∏è [DEBUG] No errors found for {group}")

        # ==========================================================
        # === Global logs ==========================================
        # ==========================================================
        output.extend(
            [
                "# üìü Logs",
                "",
                "## üì£ Info Logs",
            ]
        )

        if results.info_logs:
            for log in results.info_logs:
                output.append(f"- {log.message}")
        else:
            output.append("_No info logs_")

        output.append("")
        output.append("## ‚ùå Other Errors (not linked to specific groups)")

        # --- Prepare alias sets ---
        known_groups_full = {case.group.strip().lower() for case in results.all_cases}

        # Flatten all group aliases from earlier
        known_aliases = set()
        for g in known_groups_full:
            short = g.split("/", 1)[-1]
            known_aliases |= {
                g,
                short,
                f"geh_calculated_measurements/{short}",
                f"calculated_measurements/{short}",
            }

        # --- Identify unassigned errors ---
        other_errors = []
        for err in results.error_logs:
            tags = extract_bracket_tags(err.message)
            # Skip if any tag matches a known group alias
            if any(t in known_aliases for t in tags):
                continue
            # Skip the generic 'geh_calculated_measurements' prefix tag
            if "geh_calculated_measurements" in tags and len(tags) == 2:
                # means it's something like [geh_calculated_measurements][???]
                # and ??? wasn't a known alias ‚Äî still count as "other"
                pass
            other_errors.append(err.message)

        if other_errors:
            for err in other_errors:
                output.append(f"- {err}")
        else:
            output.append("_No other errors_")

        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text("\n".join(output), encoding="utf-8")
        print("‚úÖ [DEBUG] Markdown generation completed successfully.")
